{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffcdf006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4fa0626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a75002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7168f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------+------+\n",
      "|customer_id|   name|         visited_on|amount|\n",
      "+-----------+-------+-------------------+------+\n",
      "|          1|   Jhon|2019-01-01 00:00:00|   100|\n",
      "|          2| Daniel|2019-01-02 00:00:00|   110|\n",
      "|          3|   Jade|2019-01-03 00:00:00|   120|\n",
      "|          4| Khaled|2019-01-04 00:00:00|   130|\n",
      "|          5|Winston|2019-01-05 00:00:00|   110|\n",
      "|          6|  Elvis|2019-01-06 00:00:00|   140|\n",
      "|          7|   Anna|2019-01-07 00:00:00|   150|\n",
      "|          8|  Maria|2019-01-08 00:00:00|    80|\n",
      "|          9|   Jaze|2019-01-09 00:00:00|   110|\n",
      "|          1|   Jhon|2019-01-10 00:00:00|   130|\n",
      "|          3|   Jade|2019-01-10 00:00:00|   150|\n",
      "+-----------+-------+-------------------+------+\n",
      "\n",
      "[('customer_id', 'int'), ('name', 'string'), ('visited_on', 'timestamp'), ('amount', 'int')]\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"visited_on\", DateType(), True),\n",
    "    StructField(\"amount\", IntegerType(), True)\n",
    "])\n",
    "data = [\n",
    "    (1, \"Jhon\", datetime.strptime(\"2019-01-01\", \"%Y-%m-%d\"), 100),\n",
    "    (2, \"Daniel\", datetime.strptime(\"2019-01-02\", \"%Y-%m-%d\"), 110),\n",
    "    (3, \"Jade\", datetime.strptime(\"2019-01-03\", \"%Y-%m-%d\"), 120),\n",
    "    (4, \"Khaled\", datetime.strptime(\"2019-01-04\", \"%Y-%m-%d\"), 130),\n",
    "    (5, \"Winston\", datetime.strptime(\"2019-01-05\", \"%Y-%m-%d\"), 110),\n",
    "    (6, \"Elvis\", datetime.strptime(\"2019-01-06\", \"%Y-%m-%d\"), 140),\n",
    "    (7, \"Anna\", datetime.strptime(\"2019-01-07\", \"%Y-%m-%d\"), 150),\n",
    "    (8, \"Maria\", datetime.strptime(\"2019-01-08\", \"%Y-%m-%d\"), 80),\n",
    "    (9, \"Jaze\", datetime.strptime(\"2019-01-09\", \"%Y-%m-%d\"), 110),\n",
    "    (1, \"Jhon\", datetime.strptime(\"2019-01-10\", \"%Y-%m-%d\"), 130),\n",
    "    (3, \"Jade\", datetime.strptime(\"2019-01-10\", \"%Y-%m-%d\"), 150)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df = df.withColumn(\"visited_on\", col(\"visited_on\").cast(\"timestamp\"))\n",
    "df.show()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b25b3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a66ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|         visited_on|amount|\n",
      "+-------------------+------+\n",
      "|2019-01-01 00:00:00|   100|\n",
      "|2019-01-02 00:00:00|   110|\n",
      "|2019-01-03 00:00:00|   120|\n",
      "|2019-01-04 00:00:00|   130|\n",
      "|2019-01-05 00:00:00|   110|\n",
      "|2019-01-06 00:00:00|   140|\n",
      "|2019-01-07 00:00:00|   150|\n",
      "|2019-01-08 00:00:00|    80|\n",
      "|2019-01-09 00:00:00|   110|\n",
      "|2019-01-10 00:00:00|   280|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT visited_on, SUM(amount) as amount\n",
    "    FROM Customer\n",
    "    GROUP BY visited_on\n",
    "    \"\"\"\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be300069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n",
      "|         visited_on|sum_seven_days|\n",
      "+-------------------+--------------+\n",
      "|2019-01-01 00:00:00|           100|\n",
      "|2019-01-02 00:00:00|           210|\n",
      "|2019-01-03 00:00:00|           330|\n",
      "|2019-01-04 00:00:00|           460|\n",
      "|2019-01-05 00:00:00|           570|\n",
      "|2019-01-06 00:00:00|           710|\n",
      "|2019-01-07 00:00:00|           860|\n",
      "|2019-01-08 00:00:00|           840|\n",
      "|2019-01-09 00:00:00|           840|\n",
      "|2019-01-10 00:00:00|          1000|\n",
      "+-------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:42:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT visited_on, SUM(amount) OVER (ORDER BY visited_on RANGE BETWEEN interval 6 day preceding AND CURRENT ROW) AS sum_seven_days\n",
    "    FROM (SELECT visited_on, SUM(amount) as amount\n",
    "    FROM Customer\n",
    "    GROUP BY visited_on) AS sum_by_date\n",
    "    \"\"\"\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c4325e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/21 19:41:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+--------------+\n",
      "|         visited_on|amount|average_amount|\n",
      "+-------------------+------+--------------+\n",
      "|2019-01-07 00:00:00|   860|        122.86|\n",
      "|2019-01-08 00:00:00|   840|         120.0|\n",
      "|2019-01-09 00:00:00|   840|         120.0|\n",
      "|2019-01-10 00:00:00|  1000|        142.86|\n",
      "+-------------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT visited_on, sum_seven_days AS amount, ROUND(sum_seven_days/7, 2) AS average_amount\n",
    "    FROM (SELECT visited_on, SUM(amount) OVER (ORDER BY visited_on RANGE BETWEEN interval 6 day preceding AND CURRENT ROW) AS sum_seven_days\n",
    "    FROM (SELECT visited_on, SUM(amount) as amount\n",
    "    FROM Customer\n",
    "    GROUP BY visited_on) AS sum_by_date) as result\n",
    "    WHERE DATEDIFF(visited_on, (SELECT MIN(visited_on) FROM Customer)) >= 6 \n",
    "    \"\"\"\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ae883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
